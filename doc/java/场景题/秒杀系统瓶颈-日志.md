# 秒杀系统瓶颈-日志

大家也知道， 现在八股文问的不多了，有小伙伴去面试遇到这样的情况：说你做过电商项目， 好，  我问你秒杀系统QPS达到10万并发，怎么记录日志，  你要知道 一个请求从进入秒杀服务到处理失败或者成功，至少会产生两条日志。也就是说，高峰期间，一个秒杀节点每秒产生的日志可能达到 30 万条以上。   你怎么处理？   直接懵逼了。


一块性能比较好的固态硬盘， 他的每秒的读写次数（也就是IOPS）大概呢在 3 万左右。也就是说，那在秒杀峰值流量时的每秒日志条数是固态硬盘 IOPS 的 10 倍，磁盘都扛不住啊！！，更别说通过网络写入到监控系统中。
所以所以这里的瓶颈是：

- 每秒日志量远高于磁盘 IOPS，直接写磁盘会影响服务性能和稳定性
- 大量日志导致服务频繁分配，频繁释放相关对象的内存，影响服务性能。
-  在高负载下，日志系统可能会出现延迟,服务异常退出会导致 未写入磁盘的日志数据可能会丢失。

**那解决解决方案呢， 我给你提供3种，具体的细节可以在评论区扣666详细学习。**

- 1.通过Tmpfs，这是我比较推荐的，大道至简！ 说白了就是一个临时文件系统，它是一种基于内存的文件系统。我们可以将秒杀服务写日志的文件放在临时文件系统中。相比直接写磁盘的话，这种临时文件系统中写日志的性能至少能提升 100 倍，每当日志文件达到 20MB 的时候，就将日志文件转移到磁盘上，并将临时文件系统中的日志文件清空；  
- 2.通过内存池设计，将给logger分配缓冲区，每一次的新写可以复用Logger对象；
- 3.参考kafka的缓冲池设计，当缓冲区达到大小和间隔时长临界值时，调用Flush函数，减少丢失的风险；

好，如果视频对你有帮助， 可以给我3连支持， 下期见！


> 原文: <https://www.yuque.com/tulingzhouyu/db22bv/zz696v48nlgwtxk9>